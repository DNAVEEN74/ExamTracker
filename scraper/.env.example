# Scraper — Environment Variables
# Copy this to .env and fill in your values.

# ── Supabase ──────────────────────────────────────────────────────────────────
SUPABASE_URL=
SUPABASE_SERVICE_ROLE_KEY=

# ── Main App Webhook ──────────────────────────────────────────────────────────
# Points to /api/webhooks/new-pdf on your Vercel deployment
PARSING_WEBHOOK_URL=https://your-app.vercel.app/api/webhooks/new-pdf
# Must match SCRAPER_WEBHOOK_SECRET in the frontend .env.local
SCRAPER_WEBHOOK_SECRET=

# ── Scrape Config ─────────────────────────────────────────────────────────────
# Set per Railway cron service — do not set in code
PRIORITY_FILTER=P0
# SITE_ID=ssc      ← single site for local debugging

SCRAPE_CONCURRENCY=3
REQUEST_DELAY_MS=2000
REQUEST_TIMEOUT_MS=30000
LOG_LEVEL=info

# ── PDF Lifecycle ─────────────────────────────────────────────────────────────
# PDFs are temp-stored in Supabase Storage only until the main app parses them.
# The SHA-256 hash stays in pdf_hashes table FOREVER (prevents re-scraping).
# If a webhook fails and the PDF file is not deleted by the main app within
# PDF_TTL_HOURS, a Railway cron can clean up orphaned files.
PDF_TTL_HOURS=24
